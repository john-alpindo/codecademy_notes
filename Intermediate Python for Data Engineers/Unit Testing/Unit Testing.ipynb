{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing\n",
    "## Introduction to Testing\n",
    "**Unit Testing** is a software testing method by which individual units of source code are tested to determine whether they are fit for use. A unit is the smallest testable part of any software. It usually has one or a few inputs and usually a single output.\n",
    "\n",
    "Testing generally be divided into two categories:\n",
    "- **Manual Testing**: This is the process of manually testing software for defects. It requires a tester to play the role of an end user and use most of all features of the application to ensure correct behavior.\n",
    "- **Automated Testing**: This is the process of testing the software using an automation tool. It is used to write and execute test cases. It is faster, reliable, and more efficient than manual testing.\n",
    "\n",
    "## The `assert` Statement\n",
    "The `assert` statement is used to check if a condition is `True`. If the condition is `False`, the program will raise an `AssertionError` with an optional error message.\n",
    "\n",
    "```text\n",
    "assert <condition>, 'Message if condition is not met'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected times_ten(20) to return 200, instead got 2000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m number \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m times_ten(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected times_ten(20) to return 200, instead got \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(result)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected times_ten(20) to return 200, instead got 2000"
     ]
    }
   ],
   "source": [
    "def times_ten(number):\n",
    "    return number * 100\n",
    "\n",
    "result = times_ten(20)\n",
    "assert result == 200, 'Expected times_ten(20) to return 200, instead got ' + str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `assert` statement is a quick way to test code during development. It is not a replacement for proper unit testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing\n",
    "A test validates that the code is working as expected. It is a piece of code that checks the correctness of another piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unit we want to test\n",
    "def times_ten(number):\n",
    "    return number * 10\n",
    "\n",
    "# A unit test function with a single test case\n",
    "def test_multiply_ten_by_zero():\n",
    "    assert times_ten(0) == 0, 'Expected times_ten(0) to return 0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach is to create test cases for specific edge cases. An edge case is a scenario that is not commonly encountered and may cause the program to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiply_ten_by_one_million():\n",
    "    assert times_ten(1000000) == 10000000, 'Expected times_ten(1000000) to return 10000000'\n",
    "\n",
    "def test_multiply_ten_by_negative_number():\n",
    "    assert times_ten(-10) == -100, 'Expected times_ten(-10) to return -100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a many test cases for a single function. Each test case should test a different scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python's `unittest` Framework\n",
    "\n",
    "The previous examples were simple and easy to understand, but they are not scalable. As the codebase grows, it becomes harder to manage the tests. Python's `unittest` framework provides a more organized way to write tests.\n",
    "\n",
    "Let's refactor the previous examples using the `unittest` framework.\n",
    "\n",
    "```python\n",
    "import unittest \n",
    "\n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    pass\n",
    "```\n",
    "The `unittest` framework requires us to create a class that inherits from `unittest.TestCase`. Each test is a method that starts with the word `test`.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    def test_multiply_ten_by_zero(self):\n",
    "        pass\n",
    "\n",
    "    def test_multiply_ten_by_one_million(self):\n",
    "        pass\n",
    "\n",
    "    def test_multiply_ten_by_negative_number(self):\n",
    "        pass\n",
    "```\n",
    "The `unittest` framework will automatically run all methods that start with the word `test`.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    def test_multiply_ten_by_zero(self):\n",
    "        self.assertEqual(times_ten(0), 0, 'Expected times_ten(0) to return 0')\n",
    "\n",
    "    def test_multiply_ten_by_one_million(self):\n",
    "        self.assertEqual(times_ten(1000000), 10000000, 'Expected times_ten(1000000) to return 10000000')\n",
    "\n",
    "    def test_multiply_ten_by_negative_number(self):\n",
    "        self.assertEqual(times_ten(-10), -100, 'Expected add_times_ten(-10) to return -100')\n",
    "```\n",
    "Lastly, we need to change the `assert` statements to `self.assertEqual` and call the `unittest.main()` method to run the tests.\n",
    "\n",
    "```python\n",
    "# Run the tests\n",
    "unittest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert Methods I: Equality and Membership\n",
    "\n",
    "| Method                | Equivalent        |\n",
    "|-----------------------|-------------------|\n",
    "| self.assertEqual(2, 5) | assert 2 == 5    |\n",
    "| self.assertIn(5, [1, 2, 3]) | assert 5 in [1, 2, 3] |\n",
    "| self.assertTrue(0)   | assert bool(0) is True |\n",
    "\n",
    "## Assert Methods II: Quantitative Methods\n",
    "\n",
    "| Method                        | Equivalent               |\n",
    "|------------------------------|--------------------------|\n",
    "| self.assertLess(2, 5)        | assert 2 < 5            |\n",
    "| self.assertAlmostEqual(.22, .225) | assert round(.22 - .225, 7) == 0 |\n",
    "\n",
    "The `assertAlmostEqual` method checks that the difference between two numbers, when rounded to 7 decimal places, is zero. In this case, the test will pass.\n",
    "\n",
    "## Assert Methods III: Exception and Warning Methods\n",
    "\n",
    "- self.assertRaises(specificException, function, functionArguments...)\n",
    "- self.assertWarns(specificWarning, function, functionArguments...)\n",
    "\n",
    "Complete List: [unittest](https://docs.python.org/3/library/unittest.html#unittest.TestCase.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterizing Tests\n",
    "By parameterizing tests, we can run the same test with different inputs. This is useful when we have many test cases that follow the same pattern.\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "# The function we want to test\n",
    "def times_ten(number):\n",
    "    return number * 100\n",
    "\n",
    "# Our test class\n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    \n",
    "    # A test method\n",
    "    def test_times_ten(self):\n",
    "        for num in [0, 1000000, -10]:\n",
    "            with self.subTest():\n",
    "                expected_result = num * 10\n",
    "                message = 'Expected times_ten(' + str(num) + ') to return ' + str(expected_result)\n",
    "                self.assertEqual(times_ten(num), expected_result, message)\n",
    "```\n",
    "The `subTest` method allows us to run the same test with different inputs. If the test fails, the `subTest` method will provide more information about which input caused the failure.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# ... more code above..\n",
    "\n",
    "for num in [0, 1000000, -10]:\n",
    "  with self.subTest(num):\n",
    "\n",
    "# ... more code below ....\n",
    "```\n",
    "Optionally, we can give our subtests an argument for better readability of the error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fixtures\n",
    "A **test fixture** is a piece of code that sets up the environment for a test. It guarantees that the test will run under controlled conditions.\n",
    "\n",
    "The `unittest` framework provides two methods to set up and tear down fixtures:\n",
    "- `setUp`: This method will run before each test method.\n",
    "- `tearDown`: This method will run after each test method.\n",
    "\n",
    "```python\n",
    "def power_cycle_device():\n",
    "  print('Power cycling bluetooth device...')\n",
    "\n",
    "class BluetoothDeviceTests(unittest.TestCase):\n",
    "  def setUp(self):\n",
    "    power_cycle_device()\n",
    "\n",
    "  def test_feature_a(self):\n",
    "    print('Testing Feature A')\n",
    "\n",
    "  def test_feature_b(self):\n",
    "    print('Testing Feature B')\n",
    "\n",
    "  def tearDown(self):\n",
    "    power_cycle_device()\n",
    "```\n",
    "In this example, the `power_cycle_device` function will run before and after each test method. The device's Bluetooth module can sometimes become unresponsive, so power cycling it is a good way to ensure that the tests run correctly. This ensures that the device is in a known state before each test.\n",
    "\n",
    "```text\n",
    "Power cycling bluetooth device...\n",
    "Testing Feature A\n",
    "Power cycling bluetooth device...\n",
    ".Power cycling bluetooth device...\n",
    "Testing Feature B\n",
    "Power cycling bluetooth device...\n",
    ".\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Perhaps our tests would be efficient if we power cycle the device before and after each test. We can use the `setUpClass` and `tearDownClass` methods to run the fixture only once.\n",
    "\n",
    "```python\n",
    "def power_cycle_device():\n",
    "    print('Power cycling bluetooth device...')\n",
    "\n",
    "class BluetoothDeviceTests(unittest.TestCase):\n",
    "  @classmethod\n",
    "  def setUpClass(cls):\n",
    "    power_cycle_device()\n",
    "\n",
    "  def test_feature_a(self):\n",
    "    print('Testing Feature A')\n",
    "\n",
    "  def test_feature_b(self):\n",
    "    print('Testing Feature B')\n",
    "\n",
    "  @classmethod\n",
    "  def tearDownClass(cls):\n",
    "    power_cycle_device()\n",
    "```\n",
    "Here's the refactored code. We replaced the `setUp` and `tearDown` methods with `setUpClass` and `tearDownClass`. The `@classmethod` decorator is used to indicate that the method is a class method. We changed the argument from `self` to `cls` to indicate that it is a class method.\n",
    "\n",
    "```text\n",
    "Power cycling bluetooth device...\n",
    "Testing Feature A\n",
    "Testing Feature B\n",
    "Power cycling bluetooth device...\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "It's generally good practice to create fixtures that run before and after each test method. However, there are cases where fixture has a large cost in terms of time or resources. In these cases, it's better to use `setUpClass` and `tearDownClass`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipping Tests\n",
    "\n",
    "Sometimes, we have tests that should only run under certain conditions. For example, we have a group of tests that should only run on Windows. We can skip these tests on other operating systems.\n",
    "\n",
    "\n",
    "The `unittest` framework provides two ways to skip tests:\n",
    "- `@unittest` skip decorator\n",
    "- `skipTest()` method\n",
    "\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "class LinuxTests(unittest.TestCase):\n",
    "\n",
    "    @unittest.skipUnless(sys.platform.startswith(\"linux\"), \"This test only runs on Linux\")\n",
    "    def test_linux_feature(self):\n",
    "        print(\"This test should only run on Linux\")\n",
    "\n",
    "    @unittest.skipIf(not sys.platform.startswith(\"linux\"), \"This test only runs on Linux\")\n",
    "    def test_other_linux_feature(self):\n",
    "        print(\"This test should only run on Linux\")\n",
    "\n",
    "    @unittest.skip(\"This test is not ready yet\")\n",
    "    def test_incomplete_feature(self):\n",
    "        print(\"This test is not ready yet\")\n",
    "```\n",
    "\n",
    "- the `skipUnless` option skips the test if the condition evaluates to `False`\n",
    "- the `skipIf` option skips the test if the condition evaluates to `True`\n",
    "- the `skip` option skips the test unconditionally\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "class LinuxTests(unittest.TestCase):\n",
    "\n",
    "    def test_linux_feature(self):\n",
    "        if not sys.platform.startswith(\"linux\"):\n",
    "            self.skipTest(\"Test only runs on Linux\")\n",
    "```\n",
    "\n",
    "Here we call the `skipTest` method to skip the test if the condition is not met.\n",
    "\n",
    "When the condition for skipping a test are too complicated to be expressed in a single line, it's better to use the `skipTest` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Failures\n",
    "\n",
    "Expected failures are tests that are expected to fail. This is useful when we have a known bug that we plan to fix in the future.\n",
    "\n",
    "```python\n",
    "class FeatureTests(unittest.TestCase):\n",
    "\n",
    "    @unittest.expectedFailure\n",
    "    def test_broken_feature(self):\n",
    "        raise Exception(\"This test is going to fail\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```text\n",
    "x\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.000s\n",
    "\n",
    "OK (expected failures=1)\n",
    "```\n",
    "\n",
    "\n",
    "The test failure did not cause the test suite to fail. The test was marked as an expected failure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
