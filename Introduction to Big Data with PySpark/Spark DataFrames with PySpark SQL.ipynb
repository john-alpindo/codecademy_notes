{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spark DataFrames\n",
    "\n",
    "PySpark SQL DataFrame is a distributed collection of data organized into named columns. Under the hood, DataFrames are built on top of RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `rdd.toDF()`\n",
    "The `toDF()` method is used to convert an RDD to DataFrame. The method is available on RDD of Row objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD from a list\n",
    "hrly_views_rdd  = spark.sparkContext.parallelize([\n",
    "    [\"Betty_White\" , 288886],\n",
    "    [\"Main_Page\", 139564],\n",
    "    [\"New_Year's_Day\", 7892],\n",
    "    [\"ABBA\", 8154]\n",
    "])\n",
    "\n",
    "# Convert RDD to DataFrame\n",
    "hrly_views_df = hrly_views_rdd\\\n",
    "    .toDF([\"article_title\", \"view_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.show()`\n",
    "\n",
    "The `show()` method is used to display the content of the DataFrame. By default, it shows the first 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrly_views_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "+--------------+-----------+\n",
    "| article_title| view_count|\n",
    "+--------------+-----------+\n",
    "|   Betty_White|     288886|\n",
    "|     Main_Page|     139564|\n",
    "|New_Year's_Day|       7892|\n",
    "|          ABBA|       8154|\n",
    "+--------------+-----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.rdd`\n",
    "\n",
    "The `rdd` attribute is used to convert a DataFrame to RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access DataFrame's underlying RDD\n",
    "hrly_views_df_rdd = hrly_views_df.rdd\n",
    "\n",
    "# Check object type\n",
    "print(type(hrly_views_df_rdd)) \n",
    "# <class 'pyspark.rdd.RDD'>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
